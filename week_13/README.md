## Week 13: distributed data processing (in the cloud)

### Before class...

1. **accept the invitation** to the [Databricks](https://databricks.com) workspace for this course (check your Columbia email)


#### Advanced topics (to explore on your own)

* get comfortable with [`sparklyr`](https://spark.rstudio.com) - the package that allows you to interact with Spark from R - and get a sense of the capabilities you can explore, leveraging what you already know about data transformations using the [`tidyverse`](https://www.tidyverse.org)


<br>

---

### Complementary Resources

* [**"An Architecture for Fast and General Data Processing on Large Clusters"**](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-12.pdf): Mattei Zaharia's doctoral dissertation to get a great theoretical introduction to Spark
* [**Learning Spark, 2nd edition**](https://pages.databricks.com/rs/094-YMS-629/images/LearningSpark2.0.pdf): a book-length introduction to Spark - from zero to Spark in 12 chapters!
* [**Intro to Apache Spark**](https://www.youtube.com/watch?v=9U4ED7KQwlE&t=22s): a 60-min video to provide an easy to digest introduction to Spark for all audiences
* free [**self-paced learning courses**](https://docs.google.com/document/d/14YSH67RYaIcgHbgxs-MaDOjpWWGEfskkmDFIOREiRDs/edit) from [Databricks](https://databricks.com) for university students
* [Databricks notebook gallery](https://databricks.com/discover/notebook-gallery) featuring sample notebooks for a large range of use cases (including some using R)
* [**Mastering Spark with R**](https://therinspark.com): a book-length treatment to become a Spark expert using R
